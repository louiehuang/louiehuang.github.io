<!DOCTYPE html>
<!--[if lte IE 8 ]>
<html class="ie" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<!--<![endif]-->

<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><title>(Week7) 01 Large Margin Classification | Louie&#39;s Blog</title>
  <!-- Meta data -->
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="generator" content="Louie's Blog">
    <meta name="author" content="黄刘胤,Louie">
    <meta name="description" content="黄刘胤的博客 Louie's blog" />
    <meta name="keywords" content="黄刘胤,Louie,LouieHuang" />

    <!-- Favicon, (keep icon in root folder) -->
    <link rel="Shortcut Icon" href="/img/logo.ico" type="image/ico">

    <link rel="alternate" href="/atom.xml" title="Louie&#39;s Blog" type="application/atom+xml">
    <link rel="stylesheet" href="/css/all.css" media="screen" type="text/css">
	
    <link rel="stylesheet" href="/highlightjs/xcode.css" type="text/css">
    
    

    <!-- Custom stylesheet, (add custom styles here, always load last) -->
    <!-- Load our stylesheet for IE8 -->
    <!--[if IE 8]>
    <link rel="stylesheet" type="text/css" href="/css/ie8.css" />
    <![endif]-->

    <!-- Google Webfonts (Monserrat 400/700, Open Sans 400/600) -->
    <!--     
    <link href='//fonts.useso.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
    <link href='//fonts.useso.com/css?family=Open+Sans:400,600' rel='stylesheet' type='text/css'>
    -->
    <!-- 改为云存储 -->
    <!-- <link href='//gitimage-10031767.file.myqcloud.com/blog_image/Theme_Image/family%3DOpen%2BSans400%2C600.css' rel='stylesheet' type='text/css'> -->
    <!-- 或者本地也可以 -->
    <link href='/css/family=Open+Sans400,600.css' rel='stylesheet' type='text/css'>


    <!-- Load our fonts individually if IE8+, to avoid faux bold & italic rendering -->
    <!--[if IE]>
    <link href='http://fonts.useso.com/css?family=Montserrat:400' rel='stylesheet' type='text/css'>
    <link href='http://fonts.useso.com/css?family=Montserrat:700' rel='stylesheet' type='text/css'>
    <link href='http://fonts.useso.com/css?family=Open+Sans:400' rel='stylesheet' type='text/css'>
    <link href='http://fonts.useso.com/css?family=Open+Sans:600' rel='stylesheet' type='text/css'>
    <![endif]-->

    <!-- jQuery | Load our jQuery, with an alternative source fallback to a local version if request is unavailable -->
    <script src="/js/jquery-1.11.1.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-1.11.1.min.js"><\/script>')</script>

    <!-- Load these in the <head> for quicker IE8+ load times -->
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/js/html5shiv.min.js"></script>
    <script src="/js/respond.min.js"></script>
    <![endif]-->










  
  
  <link rel="alternate" type="application/atom+xml" title="Atom 0.3" href="atom.xml">
  
  

  <!-- Baidu -->
  <!--
  
  -->

  <!-- google统计 -->
  
  <script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-76175499-1', 'auto');
  ga('send', 'pageview');
  </script>
  

  
  <style>.col-md-8.col-md-offset-2.opening-statement img{display:none;}</style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>



<body id="index" class="lightnav animsition">

      <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- ============================ Off-canvas navigation =========================== -->

    <div class="sb-slidebar sb-right sb-style-overlay sb-momentum-scrolling">
        <div class="sb-close" aria-label="Close Menu" aria-hidden="true">
            <img src="/img/close.png" alt="Close"/>
        </div>
        <!-- header -->
        <div style="text-align:center;margin-top:15px;margin-bottom:-30px;">
            <img style="height:120px;weight:120px" src="/img/header.jpg" alt="Close"/>
            <h4 style="margin-top:10px;color:#fff;">黄刘胤 | Louie</h4>
        </div>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu">
            <li><a href="/" class="animsition-link" title="Home">Home</a></li>
            <li><a href="/archives" class="animsition-link" title="archive">archives</a></li>
            <!-- Dropdown Menu -->
			 
            
        	<li>
        		<a class="sb-toggle-submenu">Categories<span class="sb-caret"></span></a>
            	<ul class="sb-submenu">
				  	
				    <li><a href="/categories/Algorithm/" class="animsition-link">Algorithm<small>(7)</small></a></li>
				    
				    <li><a href="/categories/Algorithm-Practice/" class="animsition-link">Algorithm Practice<small>(19)</small></a></li>
				    
				    <li><a href="/categories/Dynamic-Programming/" class="animsition-link">Dynamic Programming<small>(8)</small></a></li>
				    
				    <li><a href="/categories/Information-Retrieval/" class="animsition-link">Information Retrieval<small>(9)</small></a></li>
				    
				    <li><a href="/categories/Machine-Learning/" class="animsition-link">Machine Learning<small>(23)</small></a></li>
				    
				    <li><a href="/categories/Miscellaneous/" class="animsition-link">Miscellaneous<small>(9)</small></a></li>
				    
				    <li><a href="/categories/Project-Images/" class="animsition-link">Project Images<small>(9)</small></a></li>
				    
				    <li><a href="/categories/Recommender-System/" class="animsition-link">Recommender System<small>(8)</small></a></li>
				    
				</ul>
        	</li>
			
            
            <li>
                <a class="sb-toggle-submenu">Links<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                    <li><a href="/Resume.pdf" class="animsition-link">Resume</a></li>
                    
                </ul>
            </li>
            
        </ul>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu secondary">
            <li><a href="/about.html" class="animsition-link" title="about">About Me</a></li>
            <li><a href="/atom.xml" class="animsition-link" title="rss">RSS</a></li>
        </ul>
    </div>
    
    <!-- ============================ END Off-canvas navigation =========================== -->

    <!-- ============================ #sb-site Main Page Wrapper =========================== -->

    <div id="sb-site">
        <!-- #sb-site - All page content should be contained within this id, except the off-canvas navigation itself -->

        <!-- ============================ Header & Logo bar =========================== -->

        <div id="navigation" class="navbar navbar-fixed-top">
            <div class="navbar-inner">
                <div class="container">
                    <!-- Nav logo -->
                    <div class="logo">
                        <a href="/" title="Logo" class="animsition-link">
                         <img src="/img/logo.ico" alt="Logo" width="35px;"/> 
                        </a>
                    </div>
                    <!-- // Nav logo -->
                    <!-- Info-bar -->
                    <nav>
                        <ul class="nav">
                            <li><a href="/" class="animsition-link">Louie's Blog</a></li>
                            <li class="nolink"><span>Always </span>Thinking</li>
                            
                            <li><a href="https://github.com/louiehuang" title="Github" target="_blank"><i class="icon-github"></i></a></li>
                            
                            
                            <li><a href="http://weibo.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a></li>
                            
                            
                            <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a></li>
                            
                            
                            <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a></li>
                            
                            
                            
                            <li class="nolink"><span>Welcome!</span></li>
                        </ul>
                    </nav>
                    <!--// Info-bar -->
                </div>
                <!-- // .container -->
                <div class="learnmore sb-toggle-right">More</div>
                <button type="button" class="navbar-toggle menu-icon sb-toggle-right" title="More">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar before"></span>
                <span class="icon-bar main"></span>
                <span class="icon-bar after"></span>
                </button>
            </div>
            <!-- // .navbar-inner -->
        </div>

        <!-- ============================ Header & Logo bar =========================== -->

      
<section id="intro">
    <div class="container">
        <div class="row col-md-offset-2">
            <div class="col-md-8">
    			<span class="post-meta">
      <time datetime="2018-04-08T07:00:00.000Z" itemprop="datePublished">
          2018-04-08
      </time>
    
</span>
                <h1>(Week7) 01 Large Margin Classification</h1>
            </div>
        </div>
        <div class="col-md-8 col-md-offset-2">
      		<h2 id="Large-Margin-Classification"><a href="#Large-Margin-Classification" class="headerlink" title="Large Margin Classification"></a>Large Margin Classification</h2><p>Materials are from <a href="https://www.coursera.org/learn/machine-learning/resources/Es9Qo" target="_blank" rel="external">Coursera Machine Learning by Andrew Ng</a>. </p>
<h3 id="1-Optimization-Objective"><a href="#1-Optimization-Objective" class="headerlink" title="1. Optimization Objective"></a>1. Optimization Objective</h3><p>The <strong>Support Vector Machine</strong> (SVM) is another type of <strong><em>supervised</em></strong> machine learning algorithm. It is sometimes cleaner and more powerful.</p>
<p>Recall that in logistic regression, we use the following rules:</p>
<ul>
<li>if y=1, then $h_θ(x)≈1$ and $Θ^Tx≫0$</li>
<li>if y=0, then $h_θ(x)≈0$ and $Θ^Tx≪0$</li>
</ul>
<p>Recall the cost function for (unregularized) logistic regression:</p>
<script type="math/tex; mode=display">\begin{align*}J(\theta) & = \frac{1}{m}\sum_{i=1}^m -y^{(i)} \log(h_\theta(x^{(i)})) - (1 - y^{(i)})\log(1 - h_\theta(x^{(i)}))\\ & = \frac{1}{m}\sum_{i=1}^m -y^{(i)} \log\Big(\dfrac{1}{1 + e^{-\theta^Tx^{(i)}}}\Big) - (1 - y^{(i)})\log\Big(1 - \dfrac{1}{1 + e^{-\theta^Tx^{(i)}}}\Big)\end{align*}</script><p>To make a support vector machine, we will modify the first term of the cost function $-\log(h_{\theta}(x)) = -\log\Big(\dfrac{1}{1 + e^{-\theta^Tx}}\Big)$ so that when $θ^Tx$ (from now on, we shall refer to this as <strong>z</strong>) is <strong>greater than</strong> 1, it outputs 0. Furthermore, for values of z less than 1, we shall use a straight decreasing line instead of the sigmoid curve.(In the literature, this is called a hinge loss (<a href="https://en.wikipedia.org/wiki/Hinge_loss)" target="_blank" rel="external">https://en.wikipedia.org/wiki/Hinge_loss)</a> function.)</p>
<p><img src="http://coursera-1251949857.file.myqcloud.com/MachineLearning/Images/07/1.png" alt="img"></p>
<p>Similarly, we modify the second term of the cost function $-\log(1 - h_{\theta(x)}) = -\log\Big(1 - \dfrac{1}{1 + e^{-\theta^Tx}}\Big)$ so that when z is <strong>less than</strong> -1, it outputs 0. We also modify it so that for values of z greater than -1, we use a straight increasing line instead of the sigmoid curve.</p>
<p><img src="http://coursera-1251949857.file.myqcloud.com/MachineLearning/Images/07/2.png" alt="img"></p>
<p>We shall denote these as $cost_1(z)$ and $cost_0(z)$ (respectively, note that $cost_1(z)$ is the cost for classifying when y=1, and $cost_0(z)$ is the cost for classifying when y=0), and we may define them as follows (where k is an arbitrary constant defining the magnitude of the slope of the line):</p>
<script type="math/tex; mode=display">z = \theta^Tx</script><script type="math/tex; mode=display">\text{cost}_0(z) = \max(0, k(1+z))</script><script type="math/tex; mode=display">\text{cost}_1(z) = \max(0, k(1-z))</script><p>Recall the full cost function from (regularized) logistic regression:</p>
<script type="math/tex; mode=display">J(\theta) = \frac{1}{m} \sum_{i=1}^m y^{(i)}(-\log(h_\theta(x^{(i)}))) + (1 - y^{(i)})(-\log(1 - h_\theta(x^{(i)}))) + \dfrac{\lambda}{2m}\sum_{j=1}^n \Theta^2_j</script><p>Note that the negative sign has been distributed into the sum in the above equation.</p>
<p>We may transform this into the cost function for support vector machines by substituting cost0(z) and cost1(z):</p>
<script type="math/tex; mode=display">J(\theta) = \frac{1}{m} \sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{\lambda}{2m}\sum_{j=1}^n \Theta^2_j</script><p>We can optimize this a bit by multiplying this by m (thus removing the m factor in the denominators). Note that this does not affect our optimization, since we’re simply multiplying our cost function by a positive constant (for example, minimizing $(u−5)^2+1$ gives us 5; multiplying it by 10 to make it $10(u−5)^2+10$ still gives us 5 when minimized).</p>
<script type="math/tex; mode=display">J(\theta) = \sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{\lambda}{2}\sum_{j=1}^n \Theta^2_j</script><p>Furthermore, convention dictates that we regularize using a factor C, instead of λ, like so:</p>
<script type="math/tex; mode=display">J(\theta) = C\sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j</script><p>This is equivalent to multiplying the equation by $C=\frac{1}{λ}$, and thus results in the same values when optimized. Now, when we wish to: </p>
<ul>
<li>Regularize more (<strong>reduce overfitting</strong>), we (increase $\lambda$, so $\theta$ is smaller, thus model is simpler) <em>decrease</em> C;</li>
<li>Regularize less (<strong>reduce underfitting</strong>), we (decrease $\lambda$) <em>increase</em> C.</li>
</ul>
<p><img src="http://coursera-1251949857.file.myqcloud.com/MachineLearning/Images/07/C_Theta.png" alt=""></p>
<font color="red">Finally, note that the hypothesis of the Support Vector Machine is ***not*** interpreted as the probability of y being 1 or 0 (as it is for the hypothesis of logistic regression). Instead, it outputs either 1 or 0. (In technical terms, it is a discriminant function.)</font>

<script type="math/tex; mode=display">h_\theta(x) =\begin{cases}    1 & \text{if} \ \Theta^Tx \geq 0 \\    0 & \text{otherwise}\end{cases}</script><p><br></p>
<h4 id="2-Large-Margin-Intuition"><a href="#2-Large-Margin-Intuition" class="headerlink" title="2. Large Margin Intuition"></a>2. Large Margin Intuition</h4><p>A useful way to think about Support Vector Machines is to think of them as <em>Large Margin Classifiers</em>.</p>
<ul>
<li>If y=1, we want $Θ^Tx≥1$ (not just ≥0)</li>
<li>If y=0, we want $Θ^Tx≤−1$ (not just &lt;0)</li>
</ul>
<p>Now when we set our constant $C$ to a very <strong>large</strong> value (e.g. 100,000), our optimizing function will constrain $Θ$ such that the equation A (the summation of the cost of each example) equals 0. We impose the following constraints on $Θ$:</p>
<p>$Θ^Tx≥1$ if $y=1$ and $Θ^Tx≤−1$ if $y=0$.</p>
<p>If $C$ is very large, we must choose $Θ$ parameters such that:</p>
<script type="math/tex; mode=display">\sum_{i=1}^m y^{(i)}\text{cost}_1(\Theta^Tx) + (1 - y^{(i)})\text{cost}_0(\Theta^Tx) = 0</script><p>This reduces our cost function to:</p>
<script type="math/tex; mode=display">\begin{align*} J(\theta) = C \cdot 0 + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \newline = \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j\end{align*}</script><p>Recall the decision boundary from logistic regression (the line separating the positive and negative examples). In SVMs, the decision boundary has the special property that it is <strong>as far away as possible</strong> from both the positive and the negative examples.</p>
<p><img src="http://coursera-1251949857.file.myqcloud.com/MachineLearning/Images/07/margin.png" alt=""></p>
<p>The distance of the decision boundary <strong>to the nearest example</strong> is called the <strong>margin</strong>. Since SVMs maximize this margin, it is often called a <strong><em>Large Margin Classifier</em>.</strong></p>
<p>The SVM will separate the negative and positive examples by a <strong>large margin</strong>.</p>
<p>=&gt; This large margin is only achieved when <strong>C is very large</strong>.</p>
<p>Data is <strong>linearly separable</strong> when a <strong>straight line</strong> can separate the positive and negative examples.</p>
<p>If we have <strong>outlier</strong> examples that we don’t want to affect the decision boundary, then we can <strong>reduce</strong> C.</p>
<p>Increasing and decreasing C is similar to respectively decreasing and increasing λ, and can simplify our decision boundary.</p>
<p><br></p>
<h4 id="3-Mathematics-Behind-Large-Margin-Classification"><a href="#3-Mathematics-Behind-Large-Margin-Classification" class="headerlink" title="3. Mathematics Behind Large Margin Classification"></a>3. Mathematics Behind Large Margin Classification</h4><h5 id="Vector-Inner-Product"><a href="#Vector-Inner-Product" class="headerlink" title="Vector Inner Product"></a>Vector Inner Product</h5><p>Say we have two vectors, $u$ and $v$:</p>
<script type="math/tex; mode=display">\begin{align*} u =  \begin{bmatrix} u_1 \newline u_2 \end{bmatrix} & v = \begin{bmatrix} v_1 \newline v_2 \end{bmatrix}\end{align*}</script><p>The <strong>length of vector v</strong> is denoted $||v||$, and it describes the line on a graph from origin $(0,0)$ to $(v1,v2)$.</p>
<p>The length of vector $v$ can be calculated with $\sqrt{v_1^2 + v_2^2}$  by the Pythagorean theorem.</p>
<p>The <strong>projection</strong> of vector $v$ onto vector $u$ is found by taking a right angle from $u$ to the end of $v$, creating a right triangle.</p>
<ul>
<li>$p$ = length of projection of $v$ onto the vector $u$.</li>
<li>$u^Tv= p \cdot ||u||$</li>
</ul>
<p>Note that $u^Tv = ||u|| \cdot ||v|| \cos \theta$ where $θ$ is the angle between $u$ and $v$. Also, $p = ||v|| \cos \theta$. If you substitute $p$ for $||v|| \cos \theta$, you get $u^Tv= p \cdot ||u||$.</p>
<p>So the product $u^Tv$ is equal to the length of the projection times the length of vector $u$.</p>
<p>In our example, since u and v are vectors of the same length, $u^Tv = v^Tu$.</p>
<script type="math/tex; mode=display">u^Tv = v^Tu = p \cdot ||u|| = u_1v_1 + u_2v_2</script><p>If the <strong>angle</strong> between the lines for $v$ and $u$ is <strong>greater than 90 degrees</strong>, then the projection p will be <strong>negative</strong>.</p>
<script type="math/tex; mode=display">\begin{align*}&\min_\Theta \dfrac{1}{2}\sum_{j=1}^n \Theta_j^2 \newline&= \dfrac{1}{2}(\Theta_1^2 + \Theta_2^2 + \dots + \Theta_n^2) \newline&= \dfrac{1}{2}(\sqrt{\Theta_1^2 + \Theta_2^2 + \dots + \Theta_n^2})^2 \newline&= \dfrac{1}{2}||\Theta ||^2 \newline\end{align*}</script><p>We can use the same rules to rewrite $Θ^Tx(i)$:</p>
<script type="math/tex; mode=display">\Theta^Tx^{(i)} = p^{(i)} \cdot ||\Theta || = \Theta_1x_1^{(i)} + \Theta_2x_2^{(i)} + \dots + \Theta_n x_n^{(i)}</script><p>So we now have a new <strong>optimization objective</strong> by substituting $p^{(i)} \cdot ||\Theta ||$ in for $\Theta^Tx^{(i)}$:</p>
<ul>
<li>If y=1, we want $p^{(i)} \cdot ||\Theta || \geq 1$</li>
<li>If y=0, we want $p^{(i)} \cdot ||\Theta || \leq -1$</li>
</ul>
<p>The reason this causes a “large margin” is because: <strong>the vector for $Θ$ is perpendicular to the decision boundary.</strong> In order for our optimization objective (above) to hold true, we need the absolute value of our projections $p^{(i)}$ to be as large as possible.</p>
<p>If $Θ_0=0$, then all our decision boundaries will intersect (0,0). If $\Theta_0 \neq 0$, the support vector machine will still find a large margin for the decision boundary.</p>

            <div class="clearfix"></div>
            <hr class="nogutter">
        </div>
        <nav class="pagination" role="pagination">
    
    <a class="pull-left" href="/Machine-Learning/07_02_Kernels/" style="float: left;">
        ← (Week7) 02 Kernels
    </a>
    
    
    <a class="pull-right" href="/uncategorized/Solr Steps/">
         →
    </a>
    
</nav>

        <!-- not using this
            <div class="duoshuo">
<div class="ds-thread" data-thread-key="Machine-Learning/07_01_LargeMarginClassification/" data-title="(Week7) 01 Large Margin Classification" data-url="http://louie.link/Machine-Learning/07_01_LargeMarginClassification/"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"louiehuang"};
(function() {
	var ds = document.createElement('script');
	ds.type = 'text/javascript';ds.async = true;
	ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
	ds.charset = 'UTF-8';
	(document.getElementsByTagName('head')[0] 
	 || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script>
</div>
        -->
    </div>
</section>


      
<!-- ============================ Footer =========================== -->

<footer>
    <div class="container">
            <div class="copy">
                <p>
                    &copy; 2015<script>new Date().getFullYear()>2010&&document.write("-"+new Date().getFullYear());</script>, Content By 黄刘胤,Louie. All Rights Reserved.
                </p>
                <p>Theme By Kieran</p>
            </div>
            <div class="social">
                <ul>
                    
                    <li><a href="https://github.com/louiehuang" title="Github" target="_blank"><i class="icon-github"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="http://weibo.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a>&nbsp;</li>
                    
                    
                </ul>
            </div>
            <div class="clearfix"> </div>
        </div>
</footer>

<!-- ============================ END Footer =========================== -->
      <!-- Load our scripts -->
        
<!-- Resizable 'on-demand' full-height hero -->
<script type="text/javascript">
    
    var resizeHero = function () {
        var hero = $(".cover,.heightblock"),
            window1 = $(window);
        hero.css({
            "height": window1.height()
        });
    };
    
    resizeHero();
    
    $(window).resize(function () {
        resizeHero();
    });
</script>
<script src="/js/plugins.min.js"></script><!-- Bootstrap core and concatenated plugins always load here -->
<script src="/js/jquery.flexslider-min.js"></script><!-- Flexslider plugin -->
<script src="/js/scripts.js"></script><!-- Theme scripts -->

<!-- Initiate flexslider plugin -->
<script type="text/javascript">
    $(document).ready(function($) {
      $('.flexslider').flexslider({
        animation: "fade",
        prevText: "",
        nextText: "",
        directionNav: true
      });
    });
</script>

<!-- post to baidu -->
<!-- not using this
    <script type="text/javascript">
    (function(){
        var bp = document.createElement('script');
        bp.src = '//push.zhanzhang.baidu.com/push.js';
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
    </script>
--><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
