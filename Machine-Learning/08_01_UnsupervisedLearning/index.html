<!DOCTYPE html>
<!--[if lte IE 8 ]>
<html class="ie" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<!--<![endif]-->

<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><title>(Week8) 01 Unsupervised Learning | Louie&#39;s Blog</title>
  <!-- Meta data -->
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="generator" content="Louie's Blog">
    <meta name="author" content="黄刘胤,Louie">
    <meta name="description" content="黄刘胤的博客 Louie's blog" />
    <meta name="keywords" content="黄刘胤,Louie,LouieHuang" />

    <!-- Favicon, (keep icon in root folder) -->
    <link rel="Shortcut Icon" href="/img/logo.ico" type="image/ico">

    <link rel="alternate" href="/atom.xml" title="Louie&#39;s Blog" type="application/atom+xml">
    <link rel="stylesheet" href="/css/all.css" media="screen" type="text/css">
	
    <link rel="stylesheet" href="/highlightjs/xcode.css" type="text/css">
    
    

    <!-- Custom stylesheet, (add custom styles here, always load last) -->
    <!-- Load our stylesheet for IE8 -->
    <!--[if IE 8]>
    <link rel="stylesheet" type="text/css" href="/css/ie8.css" />
    <![endif]-->

    <!-- Google Webfonts (Monserrat 400/700, Open Sans 400/600) -->
    <!--     
    <link href='//fonts.useso.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
    <link href='//fonts.useso.com/css?family=Open+Sans:400,600' rel='stylesheet' type='text/css'>
    -->
    <!-- 改为云存储 -->
    <!-- <link href='//gitimage-10031767.file.myqcloud.com/blog_image/Theme_Image/family%3DOpen%2BSans400%2C600.css' rel='stylesheet' type='text/css'> -->
    <!-- 或者本地也可以 -->
    <link href='/css/family=Open+Sans400,600.css' rel='stylesheet' type='text/css'>


    <!-- Load our fonts individually if IE8+, to avoid faux bold & italic rendering -->
    <!--[if IE]>
    <link href='http://fonts.useso.com/css?family=Montserrat:400' rel='stylesheet' type='text/css'>
    <link href='http://fonts.useso.com/css?family=Montserrat:700' rel='stylesheet' type='text/css'>
    <link href='http://fonts.useso.com/css?family=Open+Sans:400' rel='stylesheet' type='text/css'>
    <link href='http://fonts.useso.com/css?family=Open+Sans:600' rel='stylesheet' type='text/css'>
    <![endif]-->

    <!-- jQuery | Load our jQuery, with an alternative source fallback to a local version if request is unavailable -->
    <script src="/js/jquery-1.11.1.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-1.11.1.min.js"><\/script>')</script>

    <!-- Load these in the <head> for quicker IE8+ load times -->
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/js/html5shiv.min.js"></script>
    <script src="/js/respond.min.js"></script>
    <![endif]-->










  
  
  <link rel="alternate" type="application/atom+xml" title="Atom 0.3" href="atom.xml">
  
  

  <!-- Baidu -->
  <!--
  
  -->

  <!-- google统计 -->
  
  <script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-76175499-1', 'auto');
  ga('send', 'pageview');
  </script>
  

  
  <style>.col-md-8.col-md-offset-2.opening-statement img{display:none;}</style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>



<body id="index" class="lightnav animsition">

      <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- ============================ Off-canvas navigation =========================== -->

    <div class="sb-slidebar sb-right sb-style-overlay sb-momentum-scrolling">
        <div class="sb-close" aria-label="Close Menu" aria-hidden="true">
            <img src="/img/close.png" alt="Close"/>
        </div>
        <!-- header -->
        <div style="text-align:center;margin-top:15px;margin-bottom:-30px;">
            <img style="height:120px;weight:120px" src="/img/header.jpg" alt="Close"/>
            <h4 style="margin-top:10px;color:#fff;">黄刘胤 | Louie</h4>
        </div>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu">
            <li><a href="/" class="animsition-link" title="Home">Home</a></li>
            <li><a href="/archives" class="animsition-link" title="archive">archives</a></li>
            <!-- Dropdown Menu -->
			 
            
        	<li>
        		<a class="sb-toggle-submenu">Categories<span class="sb-caret"></span></a>
            	<ul class="sb-submenu">
				  	
				    <li><a href="/categories/Algorithm-Practice/" class="animsition-link">Algorithm Practice<small>(19)</small></a></li>
				    
				    <li><a href="/categories/Dynamic-Programming/" class="animsition-link">Dynamic Programming<small>(8)</small></a></li>
				    
				    <li><a href="/categories/Information-Retrieval/" class="animsition-link">Information Retrieval<small>(10)</small></a></li>
				    
				    <li><a href="/categories/Machine-Learning/" class="animsition-link">Machine Learning<small>(23)</small></a></li>
				    
				    <li><a href="/categories/Miscellaneous/" class="animsition-link">Miscellaneous<small>(9)</small></a></li>
				    
				    <li><a href="/categories/Project-Images/" class="animsition-link">Project Images<small>(9)</small></a></li>
				    
				    <li><a href="/categories/Recommender-System/" class="animsition-link">Recommender System<small>(8)</small></a></li>
				    
				</ul>
        	</li>
			
            
            <li>
                <a class="sb-toggle-submenu">Links<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                    <li><a href="/Resume.pdf" class="animsition-link">Resume</a></li>
                    
                </ul>
            </li>
            
        </ul>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu secondary">
            <li><a href="/about.html" class="animsition-link" title="about">About Me</a></li>
            <li><a href="/atom.xml" class="animsition-link" title="rss">RSS</a></li>
        </ul>
    </div>
    
    <!-- ============================ END Off-canvas navigation =========================== -->

    <!-- ============================ #sb-site Main Page Wrapper =========================== -->

    <div id="sb-site">
        <!-- #sb-site - All page content should be contained within this id, except the off-canvas navigation itself -->

        <!-- ============================ Header & Logo bar =========================== -->

        <div id="navigation" class="navbar navbar-fixed-top">
            <div class="navbar-inner">
                <div class="container">
                    <!-- Nav logo -->
                    <div class="logo">
                        <a href="/" title="Logo" class="animsition-link">
                         <img src="/img/logo.ico" alt="Logo" width="35px;"/> 
                        </a>
                    </div>
                    <!-- // Nav logo -->
                    <!-- Info-bar -->
                    <nav>
                        <ul class="nav">
                            <li><a href="/" class="animsition-link">Louie's Blog</a></li>
                            <li class="nolink"><span>Always </span>Thinking</li>
                            
                            <li><a href="https://github.com/louiehuang" title="Github" target="_blank"><i class="icon-github"></i></a></li>
                            
                            
                            <li><a href="http://weibo.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a></li>
                            
                            
                            <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a></li>
                            
                            
                            <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a></li>
                            
                            
                            
                            <li class="nolink"><span>Welcome!</span></li>
                        </ul>
                    </nav>
                    <!--// Info-bar -->
                </div>
                <!-- // .container -->
                <div class="learnmore sb-toggle-right">More</div>
                <button type="button" class="navbar-toggle menu-icon sb-toggle-right" title="More">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar before"></span>
                <span class="icon-bar main"></span>
                <span class="icon-bar after"></span>
                </button>
            </div>
            <!-- // .navbar-inner -->
        </div>

        <!-- ============================ Header & Logo bar =========================== -->

      
<section id="intro">
    <div class="container">
        <div class="row col-md-offset-2">
            <div class="col-md-8">
    			<span class="post-meta">
      <time datetime="2018-04-11T07:00:00.000Z" itemprop="datePublished">
          2018-04-11
      </time>
    
</span>
                <h1>(Week8) 01 Unsupervised Learning</h1>
            </div>
        </div>
        <div class="col-md-8 col-md-offset-2">
      		<h2 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h2><p>Materials are from <a href="https://www.coursera.org/learn/machine-learning/resources/kGWsY" target="_blank" rel="external">Coursera Machine Learning by Andrew Ng</a>. </p>
<h3 id="1-Unsupervised-Learning-Introduction"><a href="#1-Unsupervised-Learning-Introduction" class="headerlink" title="1. Unsupervised Learning: Introduction"></a>1. Unsupervised Learning: Introduction</h3><p>Unsupervised learning is contrasted from supervised learning because it uses an <strong>unlabeled</strong> training set rather than a labeled one. In other words, we don’t have the vector $y$ of expected results, we only have a dataset of features where we can find structure.</p>
<p>Clustering is good for:</p>
<ul>
<li>Market segmentation</li>
<li>Social network analysis</li>
<li>Organizing computer clusters (e.g. data center)</li>
<li>Astronomical data analysis</li>
</ul>
<p><br></p>
<h3 id="2-K-Means-Algorithm"><a href="#2-K-Means-Algorithm" class="headerlink" title="2. K-Means Algorithm"></a>2. K-Means Algorithm</h3><p>The K-Means Algorithm is the most popular and widely used algorithm for automatically grouping data into coherent subsets.</p>
<ol>
<li>Randomly initialize K points in the dataset called the <strong>cluster centroids</strong>.</li>
<li><strong>Cluster assignment:</strong> assign all examples into one of K groups based on which cluster centroid the example is closest to.</li>
<li><strong>Move centroid:</strong> compute the averages for all the points inside each of the K cluster centroid groups, then move the cluster centroid points to those averages.</li>
<li>Re-run (2) and (3) until we have found our clusters.</li>
</ol>
<p>Our main variables are:</p>
<ul>
<li>K (number of clusters)</li>
<li>Training set ${x^{(1)}, x^{(2)}, \dots,x^{(m)}}$</li>
<li>Where $x^{(i)} \in \mathbb{R}^n$</li>
</ul>
<p>Note that we <strong>will not use</strong> the $x_0=1$ convention.</p>
<p><strong>The algorithm:</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Randomly initialize K cluster centroids mu(<span class="number">1</span>), mu(<span class="number">2</span>), ..., mu(K)</span><br><span class="line">Repeat:</span><br><span class="line">   <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> to m: <span class="comment">% Cluster assignment</span></span><br><span class="line">      c(<span class="built_in">i</span>):= index (from <span class="number">1</span> to K) of cluster centroid closest to x(<span class="built_in">i</span>)</span><br><span class="line">   <span class="keyword">for</span> k = <span class="number">1</span> to K: <span class="comment">% Move centroid</span></span><br><span class="line">      mu(k):= average (mean) of points assigned to cluster k</span><br></pre></td></tr></table></figure>
<p>The <strong>first for-loop</strong> is the <strong>‘Cluster Assignment’</strong> step. We make a vector $c$ where $c^{(i)}$ represents the centroid assigned to example $x^{(i)}$.</p>
<p>We can write the operation of the Cluster Assignment step more mathematically as follows:</p>
<script type="math/tex; mode=display">c^{(i)} = argmin_k\ ||x^{(i)} - \mu_k||^2</script><p>That is, each $c^{(i)}$ contains the <strong>index of the centroid</strong> that has minimal distance to $x^{(i)}$.</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">idx</span> = <span class="title">findClosestCentroids</span><span class="params">(X, centroids)</span></span></span><br><span class="line"><span class="comment">% ...</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(X,<span class="number">1</span>)</span><br><span class="line">    min_dist = intmax(<span class="string">'int64'</span>);</span><br><span class="line">    <span class="keyword">for</span> c = <span class="number">1</span> : K</span><br><span class="line">        cur_dist = sum((X(<span class="built_in">i</span>,:) - centroids(c,:)) .^ <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span>(cur_dist &lt; min_dist)</span><br><span class="line">            min_dist = cur_dist;</span><br><span class="line">            idx(<span class="built_in">i</span>) = c;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><strong>By convention</strong>, we square the right-hand-side, which <strong>makes the function we are trying to minimize more sharply increasing.</strong> It is mostly just a convention. But a convention that helps reduce the computation load because the Euclidean distance requires a square root but it is canceled.</p>
<p>Without the square:</p>
<script type="math/tex; mode=display">||x^{(i)} - \mu_k|| = ||\quad\sqrt{(x_1^i - \mu_{1(k)})^2 + (x_2^i - \mu_{2(k)})^2 + (x_3^i - \mu_{3(k)})^2 + ...}\quad||</script><p>With the square:</p>
<script type="math/tex; mode=display">||x^{(i)} - \mu_k||^2 = ||\quad(x_1^i - \mu_{1(k)})^2 + (x_2^i - \mu_{2(k)})^2 + (x_3^i - \mu_{3(k)})^2 + ...\quad||</script><p>…so the square convention serves two purposes, <strong>minimize more sharply and less computation.</strong></p>
<p>The <strong>second for-loop</strong> is the <strong>‘Move Centroid’</strong> step where we move each centroid to the average of its group.</p>
<p>More formally, the equation for this loop is as follows:</p>
<script type="math/tex; mode=display">\mu_k = \dfrac{1}{n}[x^{(k_1)} + x^{(k_2)} + \dots + x^{(k_n)}] \in \mathbb{R}^n</script><p>Where each of $x^{(k_1)}, x^{(k_2)}, \dots, x^{(k_n)}$ are the training examples assigned to group $mμ_k$.</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">centroids</span> = <span class="title">computeCentroids</span><span class="params">(X, idx, K)</span></span></span><br><span class="line"><span class="comment">% ...</span></span><br><span class="line"><span class="keyword">for</span> c = <span class="number">1</span> : K</span><br><span class="line">    subX = <span class="built_in">find</span>(idx == c); <span class="comment">%subset of X, find points which are grouped as cluster c</span></span><br><span class="line">    centroids(c, :) = <span class="number">1</span> / <span class="built_in">size</span>(subX, <span class="number">1</span>) * sum(X(subX, :));</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>If you have a cluster centroid with <strong>0 points</strong> assigned to it, you can randomly <strong>re-initialize</strong> that centroid to a new point. You can also simply <strong>eliminate</strong> that cluster group.</p>
<p>After a number of iterations the algorithm will <strong>converge</strong>, where new iterations do not affect the clusters.</p>
<p>Note on non-separated clusters: some datasets have no real inner separation or natural structure. K-means can still evenly segment your data into K subsets, so can still be useful in this case.</p>
<p><br></p>
<h3 id="3-Optimization-Objective"><a href="#3-Optimization-Objective" class="headerlink" title="3. Optimization Objective"></a>3. Optimization Objective</h3><p>Recall some of the parameters we used in our algorithm:</p>
<ul>
<li>$c^{(i)}$ = index of cluster (1,2,…,K) to which example $x^{(i)}$ is currently assigned</li>
<li>$μ_k$= cluster centroid k ($μ_k ∈ ℝ^n$)</li>
<li>$μ_{c^{(i)}}$ = cluster centroid of cluster to which example $x^{(i)}$ has been assigned</li>
</ul>
<p>Using these variables we can define our <strong>cost function</strong>:</p>
<script type="math/tex; mode=display">J(c^{(i)},\dots,c^{(m)},\mu_1,\dots,\mu_K) = \dfrac{1}{m}\sum_{i=1}^m ||x^{(i)} - \mu_{c^{(i)}}||^2</script><p>Our <strong>optimization objective</strong> is to minimize all our parameters using the above cost function:</p>
<script type="math/tex; mode=display">min_{c,\mu}\ J(c,\mu)</script><p>That is, we are finding all the values in sets $c$, representing all our clusters, and $μ$, representing all our centroids, that will minimize <strong>the average of the distances</strong> of every training example to its corresponding cluster centroid.</p>
<p>The above cost function is often called the <strong>distortion</strong> of the training examples.</p>
<p>In the <strong>cluster assignment step</strong>, our goal is to:</p>
<p>Minimize $J(…)$ with $c^{(1)},\dots,c^{(m)}$ (holding $\mu_1,\dots,\mu_K$ fixed)</p>
<p>In the <strong>move centroid</strong> step, our goal is to:</p>
<p>Minimize $J(…)$ with $\mu_1,\dots,\mu_K$</p>
<p>With k-means, it is <strong>not possible for the cost function to sometimes increase</strong>. It should always descend.</p>
<p><br></p>
<h3 id="4-Random-Initialization"><a href="#4-Random-Initialization" class="headerlink" title="4. Random Initialization"></a>4. Random Initialization</h3><p>There’s one particular recommended method for randomly initializing your cluster centroids.</p>
<ol>
<li>Have $K&lt;m$. That is, make sure the number of your clusters is less than the number of your training examples.</li>
<li>Randomly pick $K$ training examples. (Be sure the selected examples are <strong>unique</strong>).</li>
<li>Set $\mu_1,\dots,\mu_K$ equal to these $K$ examples.</li>
</ol>
<p>K-means <strong>can get stuck in local optima</strong>. To decrease the chance of this happening, you can run the algorithm on many different random initializations. In cases where $K&lt;10$ it is strongly recommended to run a loop of random initializations.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for i = 1 to 100:</span><br><span class="line">   randomly initialize k-means</span><br><span class="line">   run k-means to get &apos;c&apos; and &apos;m&apos;</span><br><span class="line">   compute the cost function (distortion) J(c,m)</span><br><span class="line">pick the clustering that gave us the lowest cost</span><br></pre></td></tr></table></figure>
<p><br></p>
<h3 id="5-Choosing-the-Number-of-Clusters"><a href="#5-Choosing-the-Number-of-Clusters" class="headerlink" title="5. Choosing the Number of Clusters"></a>5. Choosing the Number of Clusters</h3><p>Choosing $K$ can be quite arbitrary and ambiguous.</p>
<p><strong>The elbow method</strong>: plot the cost $J$ and the number of clusters $K$. The cost function should reduce as we increase the number of clusters, and then flatten out. Choose K at the point where the cost function starts to flatten out.</p>
<p>However, fairly often, the curve is <strong>very gradual</strong>, so there’s no clear elbow. (see following right graph)</p>
<p><img src="http://coursera-1251949857.cossh.myqcloud.com/MachineLearning/Images/08/1.png" alt=""></p>
<p><strong>Note:</strong> $J$ will <strong>always</strong> decrease as K is increased. The one exception is if k-means gets stuck at a bad local optimum.</p>
<p>Another way to choose $K$ is to observe how well k-means performs on a <strong>downstream purpose</strong>. In other words, you choose $K$ that proves to be most useful for some goal you’re trying to achieve from using these clusters.</p>
<p><br></p>
<h3 id="6-Bonus-Discussion-of-the-drawbacks-of-K-Means"><a href="#6-Bonus-Discussion-of-the-drawbacks-of-K-Means" class="headerlink" title="6. Bonus: Discussion of the drawbacks of K-Means"></a>6. Bonus: Discussion of the drawbacks of K-Means</h3><p>This links to a discussion that shows various situations in which K-means gives totally correct but unexpected results: <a href="http://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means" target="_blank" rel="external">http://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means</a></p>

            <div class="clearfix"></div>
            <hr class="nogutter">
        </div>
        <nav class="pagination" role="pagination">
    
    <a class="pull-left" href="/Machine-Learning/09_01_AnomalyDetection/" style="float: left;">
        ← (Week9) 01 Anomaly Detection
    </a>
    
    
    <a class="pull-right" href="/Machine-Learning/08_02_DimensionalityReduction/">
        (Week8) 02 Dimensionality Reduction →
    </a>
    
</nav>

        <!-- not using this
            <div class="duoshuo">
<div class="ds-thread" data-thread-key="Machine-Learning/08_01_UnsupervisedLearning/" data-title="(Week8) 01 Unsupervised Learning" data-url="http://louie.link/Machine-Learning/08_01_UnsupervisedLearning/"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"louiehuang"};
(function() {
	var ds = document.createElement('script');
	ds.type = 'text/javascript';ds.async = true;
	ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
	ds.charset = 'UTF-8';
	(document.getElementsByTagName('head')[0] 
	 || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script>
</div>
        -->
    </div>
</section>


      
<!-- ============================ Footer =========================== -->

<footer>
    <div class="container">
            <div class="copy">
                <p>
                    &copy; 2015<script>new Date().getFullYear()>2010&&document.write("-"+new Date().getFullYear());</script>, Content By 黄刘胤,Louie. All Rights Reserved.
                </p>
                <p>Theme By Kieran</p>
            </div>
            <div class="social">
                <ul>
                    
                    <li><a href="https://github.com/louiehuang" title="Github" target="_blank"><i class="icon-github"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="http://weibo.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a>&nbsp;</li>
                    
                    
                </ul>
            </div>
            <div class="clearfix"> </div>
        </div>
</footer>

<!-- ============================ END Footer =========================== -->
      <!-- Load our scripts -->
        
<!-- Resizable 'on-demand' full-height hero -->
<script type="text/javascript">
    
    var resizeHero = function () {
        var hero = $(".cover,.heightblock"),
            window1 = $(window);
        hero.css({
            "height": window1.height()
        });
    };
    
    resizeHero();
    
    $(window).resize(function () {
        resizeHero();
    });
</script>
<script src="/js/plugins.min.js"></script><!-- Bootstrap core and concatenated plugins always load here -->
<script src="/js/jquery.flexslider-min.js"></script><!-- Flexslider plugin -->
<script src="/js/scripts.js"></script><!-- Theme scripts -->

<!-- Initiate flexslider plugin -->
<script type="text/javascript">
    $(document).ready(function($) {
      $('.flexslider').flexslider({
        animation: "fade",
        prevText: "",
        nextText: "",
        directionNav: true
      });
    });
</script>

<!-- post to baidu -->
<!-- not using this
    <script type="text/javascript">
    (function(){
        var bp = document.createElement('script');
        bp.src = '//push.zhanzhang.baidu.com/push.js';
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
    </script>
--><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
